{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower memory footprint\n",
    "\n",
    "https://github.com/facebookresearch/faiss/wiki/Lower-memory-footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用内存太多，我如何压缩存储?——IndexIVFPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb (100000, 64)\n",
      "xq (10000, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000.\n",
    "print('xb', xb.shape)\n",
    "# print('xb', xb[:1])\n",
    "print('xq', xq.shape)\n",
    "# print('xq', xq[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IndexFlatL2` 和 `IndexIVFFlat` 都会保存全部的向量. 为了扩展到非常大的数据集，Faiss提供了变通，基于乘积量化器（product quantizers）的有损压缩来存储向量。\n",
    "\n",
    "向量仍然存在在`Voronoi cells`, 但是它们的大小减少到你设置的字节数`m`(`d`必须是`m`的倍数).\n",
    "\n",
    "压缩是基于一个`Product Quantizer`, that can be seen as an additional level of quantization, that is applied on sub-vectors of the vectors to encode.\n",
    "\n",
    "In this case, since the vectors are not stored exactly, the distances that are returned by the search method are also approximations.\n",
    "\n",
    "> `IVF`是`Voronoi cells`，`PQ`是压缩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   78  608  159]\n",
      " [   1 1063  555  380]\n",
      " [   2  304  134   46]\n",
      " [   3   64  773  265]\n",
      " [   4  288  827  531]]\n",
      "[[1.6157436 6.1152253 6.4348025 6.564184 ]\n",
      " [1.389575  5.6771317 5.9956017 6.486294 ]\n",
      " [1.7025063 6.121688  6.189084  6.489888 ]\n",
      " [1.8057687 6.5440307 6.6684756 6.859398 ]\n",
      " [1.4920276 5.79976   6.190908  6.3791513]]\n"
     ]
    }
   ],
   "source": [
    "nlist = 100\n",
    "m = 8                             # number of subquantizers\n",
    "k = 4\n",
    "\n",
    "import faiss\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # this remains the same\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n",
    "                                    # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index.train(xb)\n",
    "index.add(xb)\n",
    "D, I = index.search(xb[:5], k)    # sanity check\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 399  210  329 1619]\n",
      " [1193   39  911  187]\n",
      " [1267  197  527  425]\n",
      " [ 184  599  466  359]\n",
      " [ 828  377  120  416]]\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 10              # make comparable with experiment above\n",
    "D, I = index.search(xq, k)     # search\n",
    "print(I[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当用训练向量搜索时，结果如下：\n",
    "```text\n",
    "[[   0   78  608  159]\n",
    " [   1 1063  555  380]\n",
    " [   2  304  134   46]\n",
    " [   3   64  773  265]\n",
    " [   4  288  827  531]]\n",
    "```\n",
    "可以看到，knn是正确的，向量的id是他们自己, 即第一列。\n",
    "```text\n",
    "[[1.6157436 6.1152253 6.4348025 6.564184 ]\n",
    " [1.389575  5.6771317 5.9956017 6.486294 ]\n",
    " [1.7025063 6.121688  6.189084  6.489888 ]\n",
    " [1.8057687 6.5440307 6.6684756 6.859398 ]\n",
    " [1.4920276 5.79976   6.190908  6.3791513]]\n",
    "```\n",
    "但是，向量与其自己的距离不是0，尽管这个距离与其近邻相比很低，即第一列与后面列的值相比很低. 这是由于压缩后有损失.\n",
    "\n",
    "本例中，我们把`64维的32位浮点（32/8*64=256 bytes）`压缩成`8字节`，即用8个字节保存64维的32位浮点数，因此, so the compression factor is 32.\n",
    "\n",
    "当用查询向量搜索时, 结果如下:\n",
    "```text\n",
    "[[ 9432  9649  9900 10287]\n",
    " [10229 10403  9829  9740]\n",
    " [10847 10824  9787 10089]\n",
    " [11268 10935 10260 10571]\n",
    " [ 9582 10304  9616  9850]]\n",
    "```\n",
    "They can be compared with the IVFFlat results above. For this case, most results are wrong, but they are in the correct area of the space, as shown by the IDs around 10000. The situation is better for real data because:\n",
    "\n",
    "对均匀分布的数据（uniform data）进行索引很难，因为它没有规律来探索cluster和降维.\n",
    "\n",
    "而对于自然数据, 语义相近的近邻通常与不相关的很接近."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简化索引的构造\n",
    "因为构建索引有点复杂，所以，Faiss提供了一个工厂函数，你用字符串就可以构造索引. The indexes above can be obtained with the following shorthand:\n",
    "```python\n",
    "index = faiss.index_factory(d, \"IVF100,PQ8\")\n",
    "```\n",
    "把`PQ4`替换成`Flat`就相当于`IndexFlat`. 当对输入向量集合进行预处理（如，PCA）时，工厂方法就特别有用. 例如, 把输入向量集合进行预处理，利用PAC降维到32维，工厂方法的字符串可写成: \"PCA32,IVF100,Flat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the next sections to get more specific information about the types of indexes, GPU faiss, coding structure, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
