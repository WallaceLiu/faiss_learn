{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faiss 索引的组合\n",
    "https://github.com/facebookresearch/faiss/wiki/Faiss-indexes-(composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本小节是Faiss更高级的应用. 通过结合前一节中描述的几种索引方法，可以获得最佳操作点."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "d = 512          \n",
    "n_data = 2000   \n",
    "np.random.seed(0) \n",
    "data = []\n",
    "mu = 3\n",
    "sigma = 0.1\n",
    "for i in range(n_data):\n",
    "    data.append(np.random.normal(mu, sigma, d))\n",
    "data = np.array(data).astype('float32')\n",
    "\n",
    "#query\n",
    "query = []\n",
    "n_query = 10\n",
    "np.random.seed(12) \n",
    "query = []\n",
    "for i in range(n_query):\n",
    "    query.append(np.random.normal(mu, sigma, d))\n",
    "query = np.array(query).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 512)\n",
      "(10, 512)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带乘积量化的cell-probe作为粗量化器\n",
    "乘积量化器（product quantizer）也可以作为粗量化器（coarse quantizer）。 This corresponds to the Multi-Index described in [The inverted multi-index, Babenko & Lempitsky, CVPR'12]. For a PQ with m segments each encoded as c centroids, the number of inverted lists is c^m. For a PQ with m segments each encoded as c centroids, the number of inverted lists is c^m. 实际使用中，一般直接让`m=2`。  \n",
    "\n",
    "In FAISS, the corresponding coarse quantizer index is the MultiIndexQuantizer. This index is special because no vector is added to it. Therefore a specific flag (quantizer_trains_alone) has to be set on the IndexIVF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1269 1028 1895  120 1267  178 1061 1972 1029 1913]\n",
      " [1398  289   70 1023 1177  940  940  969  969 1568]\n",
      " [ 345  389 1904 1992 1612 1623 1632  539  366 1805]\n",
      " [ 112  112 1412 1624  879  394 1506 1398   91  440]\n",
      " [  94 1459 1517 1723 1255   66  238 1755  472  375]\n",
      " [ 574  574 1523   91  456  296  296  444 1384  103]\n",
      " [1391  876   91 1914   78   78  969  732  732  999]\n",
      " [1662 1654  722 1070  121 1496  631 1442 1442 1738]\n",
      " [ 154   99   99   31 1237  289  661  426 1008 1727]\n",
      " [ 375 1826  610  750 1430  459 1339  471  441  818]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/maliqi/faiss/python/')\n",
    "import faiss\n",
    "\n",
    "nbits_mi = 5   # c\n",
    "M_mi = 2       # m\n",
    "coarse_quantizer_mi = faiss.MultiIndexQuantizer(d, M_mi, nbits_mi) #不需要add任何数据\n",
    "ncentroids_mi = 2 ** (M_mi * nbits_mi)\n",
    "\n",
    "index = faiss.IndexIVFFlat(coarse_quantizer_mi, d, ncentroids_mi)\n",
    "index.quantizer_trains_alone = True  #表示这是粗量化器的flag\n",
    "index.train(data)\n",
    "index.add(data)\n",
    "index.nprobe = 50\n",
    "dis, ind = index.search(query, 10)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与`IndexFlat`相比，在快速、低精度的场景，`MultiIndexQuantizer`更合适。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-filtering PQ codes with polysemous codes\n",
    "It is about 6x faster to compare codes with Hamming distances than to use a product quantizer. However, by a proper reordering of the quantization centroids, the Hamming distances between PQ codes become correlated with the true distances. The by applying a threshold on the Hamming distance, most expensive PQ code comparisons can be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " ...\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]\n",
      " [-1 -1 -1 ... -1 -1 -1]]\n",
      "[[3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]\n",
      " [3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]\n",
      " [3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]\n",
      " ...\n",
      " [3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]\n",
      " [3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]\n",
      " [3.4028235e+38 3.4028235e+38 3.4028235e+38 ... 3.4028235e+38\n",
      "  3.4028235e+38 3.4028235e+38]]\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexPQ (d, 16, 8)\n",
    "# before training\n",
    "index.do_polysemous_training = True\n",
    "index.train(data)\n",
    "\n",
    "# before searching\n",
    "index.search_type = faiss.IndexPQ.ST_polysemous\n",
    "index.polysemous_ht = 54    # the Hamming threshold\n",
    "D, I=index.search (query, 10)\n",
    "print(I)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于`IndexIVFPQ`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "index = faiss.IndexIVFPQ (coarse_quantizer, d, 16, 8)\n",
    "# before training\n",
    "index. do_polysemous_training = True\n",
    "index.train(data)\n",
    "\n",
    "# before searching\n",
    "index.polysemous_ht = 54 # the Hamming threshold\n",
    "D, I=index.search(query, 10)\n",
    "print(I)\n",
    "print(D)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若想设置合理的阈值, 记住:\n",
    "\n",
    "the threshold should be between 0 and the number of bits per code (128 = 16*8 in this case), and codes follow a binomial distribution\n",
    "\n",
    "setting the threshold to 1/2 the number of bits per code will spare 1/2 of the code comparisons, which is not enough. It should be set to a lower value (hence the 54 for 128 bit codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndexIVFPQR: 使用一个额外的乘积量化器PQ细化`IVFPQ`搜索结果\n",
    "The `IndexIVFPQR` adds an additional level of quantization (the third!) on top of an IndexIVFPQ. Similar to the IndexRefineFlat It refines the distances computed by an IndexIVFPQ and reorders the results based on these."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
