{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force search without an index\n",
    "https://github.com/facebookresearch/faiss/wiki/Brute-force-search-without-an-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of IndexFlat, the added data is just copied to the index without further encoding or organization. Therefore, it may be useful to short-circuit the indexing altogether. This makes it possible to:\n",
    "\n",
    "avoid having two copies of the same data in memory\n",
    "\n",
    "do updates on the data between searches.\n",
    "\n",
    "Faiss provides low-level functions to do the brute-force search in this context.\n",
    "\n",
    "The functions take a matrix of database vectors and a matrix of query vectors and return the k-nearest neighbors and their distances.\n",
    "\n",
    "# Brute force search on CPU\n",
    "On CPU, the relevant function is knn_L2sqr or knn_inner_product.\n",
    "\n",
    "Example usage in Python: search_without_index.py\n",
    "\n",
    "# Brute force search on GPU\n",
    "On GPU, the relevant function is bruteForceKnn. An additional advantage is that it takes both CPU and GPU resident data as input or output.\n",
    "\n",
    "An example usage in python, from pytorch GPU data is here: test_pytorch_faiss.py\n",
    "\n",
    "Note that on GPU, the synchronization is needed because Faiss uses a non-default CUDA stream. The easiest workaround is to force it to use the default stream. This is done via\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "res.setDefaultNullStreamAllDevices()\n",
    "Also, by default the amount of memory allocated by the resource object is too large for simple brute force. You can set:\n",
    "\n",
    "res.setTempMemory(64 * 1024 * 1024)\n",
    "ie. use only 64M (if that is not enough, try a few other values, according to some reports setting to 0 works just fine).\n",
    "\n",
    "# Combining the results from several searches\n",
    "When the number of query vectors is limited, the best indexing method is to not index at all and use brute force search. This can be problematic when the dataset vectors do not fit in RAM or GPU RAM. In that case, it is efficient to search the xq vectors in slices xb of the database vectors. To maintain the top-k nearest neighbors seen so far, use a ResultHeap structure:\n",
    "\n",
    "https://github.com/facebookresearch/faiss/blob/master/benchs/bench_all_ivf/datasets.py#L75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
