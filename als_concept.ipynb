{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ceys/jdml/wiki/ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、算法描述\n",
    "### 1.原理 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题描述 \n",
    "ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。与传统的矩阵分解SVD方法来分解矩阵R($R\\in \\mathbb{R}^{m\\times n}$)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 $\\tilde{R} = XY$ 来逼近矩阵R，其中 ，$X\\in \\mathbb{R}^{m\\times d}$，$Y\\in \\mathbb{R}^{d\\times n}$，d 表示降维后的维度，一般 d<<r，r表示矩阵 R 的秩，$r<<min(m,n)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目标函数\n",
    "为了找到低维矩阵X,Y最大程度地逼近矩分矩阵R，最小化下面的平方误差损失函数。\n",
    "$$L(X,Y) = \\sum_{u,i}(r_{ui} - x_{u}^{T}y_{i})^{2}......(1)$$\n",
    "\n",
    "为防止过拟合给公式 (1) 加上正则项，公式改下为： $$L(X,Y) = \\sum_{u,i}(r_{ui} - x_{u}^{T}y_{i})^{2} + \\lambda (\\left | x_{u}\\right |^{2} +　\\left | y_{i}\\right |^{2})......(2)$$\n",
    "\n",
    "其中$x_{u}\\in \\mathbb{R}^{d}，y_{i}\\in \\mathbb{R}^{d}$，$1\\leqslant u\\leqslant m$，$1\\leqslant i\\leqslant n$，$\\lambda$是正则项的系数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型求解\n",
    "\n",
    "固定Y，对$x_{u}$ 求导 $\\frac{\\partial L(X,Y)}{\\partial x_{u}} = 0$，得到求解$x_{u}$的公式\n",
    "\n",
    "$$x_{u} = (Y^{T}Y + \\lambda I )^{-1}Y^{T}r(u)......(3)$$\n",
    "\n",
    "同理固定X,可得到求解$y_{i}$的公式\n",
    "\n",
    "$$y_{i} = (X^{T}X + \\lambda I )^{-1}X^{T}r(i)......(4)$$\n",
    "\n",
    "其中，$r_{u}\\in \\mathbb{R}^{n}$,$r_{i}\\in \\mathbb{R}^{m}$,I表示一个d * d的单位矩阵。\n",
    "\n",
    "基于公式(3)、(4)，首先随机初始化矩阵X，然后利用公式(3)更新Y，接着用公式(4)更新X，直到计算出的RMSE(均方根误差)值收敛或迭代次数足够多而结束迭代为止。\n",
    "\n",
    "其中，$\\tilde{R} = XY$，$RMSE = \\sqrt{\\frac{\\sum (R - \\tilde{R})^{2}}{N}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS-WR模型 \n",
    "以上模型适用于用户对商品的有明确的评分矩阵的场景，然而很多情况下用户没有明确的反馈对商品的偏好，而是通过一些行为隐式的反馈。比如对商品的购买次数、对电视节目收看的次数或者时长，这时我们可以推测次数越多，看得时间越长，用户的偏好程度越高，但是对于没有购买或者收看的节目，可能是由于用户不知道有该商品，或者没有途径获取该商品，我们不能确定的推测用户不喜欢该商品。ALS-WR通过置信度的权重来解决此问题，对于我们更确信用户偏好的项赋予较大的权重，对于没有反馈的项，赋予较小的权重。模型如下\n",
    "\n",
    "ALS-WR目标函数\n",
    "\n",
    "$\\underset{x_{u},y_{i}}{min} L(X,Y) = \\sum_{u,i}c_{ui}(p_{ui} - x_{u}^{T}y_{i})^{2} + \\lambda (\\left | x_{u}\\right |^{2} +　\\left | y_{i}\\right |^{2})......(5)$\n",
    "\n",
    "其中 $$p_{ui} = \\begin{cases} & \\text{1 if } r_{ui} > 0 \\ & \\text{0 if } r_{ui} = 0 \\end{cases}$$\n",
    "\n",
    "$c_{ui} = 1 + \\alpha r_{ui}$，$\\alpha$是置信度系数\n",
    "\n",
    "通过最小二乘法求解\n",
    "\n",
    "$$x_{u} = (Y^{T}C^{u}Y + \\lambda I )^{-1}Y^{T}C^{u}r(u)......(6)$$\n",
    "\n",
    "$$y_{i} = (X^{T}C^{i}X + \\lambda I )^{-1}X^{T}C^{i}r(i)......(7)$$\n",
    "\n",
    "其中$C^{u}$是一$n\\times n$维的个对角矩阵，$C_{ii}^{u} = c_{ui}$; 其中$C^{u}$是一$m\\times m$维的个对角矩阵，$C_{ii}^{u} = c_{ui}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 与其他矩阵分解算法的比较\n",
    "\n",
    "在实际应用中，由于待分解的矩阵常常是非常稀疏的，与SVD相比，ALS能有效的解决过拟合问题。\n",
    "\n",
    "基于ALS的矩阵分解的协同过滤算法的可扩展性也优于SVD。\n",
    "\n",
    "与随机梯度下降的求解方式相比，一般情况下随机梯度下降比ALS速度快；但有两种情况ALS更优于随机梯度下降：1)当系统能够并行化时，ALS的扩展性优于随机梯度下降法。2）ALS-WR能够有效的处理用户对商品的隐式反馈的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.伪代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73606055 1.19692412 0.41669386 0.29557827]\n",
      " [0.33907711 0.56859977 0.19514866 0.16354529]\n",
      " [0.24112613 0.42577111 0.14274748 0.15037359]\n",
      " [0.56403899 0.78064976 0.29399376 0.00935574]\n",
      " [0.38555231 0.73082448 0.2375243  0.32000485]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def mf_als(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps): \n",
    "        for i in range(len(P)):                              \n",
    "            e = 0\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    R = [\n",
    "     [5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    "    R = numpy.array(R)\n",
    "    N, M, K = len(R), len(R[0]), 2\n",
    "    P = numpy.random.rand(N,K)\n",
    "    Q = numpy.random.rand(M,K)\n",
    "\n",
    "    nP, nQ = mf_als(R, P, Q, K)\n",
    "    print(numpy.dot(nP, nQ.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.并行化方法:\n",
    "\n",
    "整体思路就是把矩阵拆成行向量，分别来做最小二乘参数估计。\n",
    "\n",
    "伪代码中，所有数据都被广播到了集群节点。实际代码中，只会向各节点分发其运算能用到的部分数据。\n",
    "\n",
    "```python\n",
    "# M： item个数， U： user个数， F： 分解矩阵的秩\n",
    "# 初始化评分矩阵\n",
    "R = matrix(rand(M, F)) * matrix(rand(U, F).T)\n",
    "ms = matrix(rand(M ,F))\n",
    "us = matrix(rand(U, F))\n",
    "\n",
    "# 将评分矩阵，item矩阵，user矩阵广播到所有节点\n",
    "Rb = sc.broadcast(R)\n",
    "msb = sc.broadcast(ms)\n",
    "usb = sc.broadcast(us)\n",
    "\n",
    "# 指定遍历次数ITERATIONS\n",
    "for i in range(ITERATIONS):\n",
    "\t# 固定user矩阵，分布式求解item矩阵\n",
    "\t# 每个节点计算M/slices个items\n",
    "    ms = sc.parallelize(range(M), slices) \\\n",
    "           .map(lambda x: update(x, msb.value[x, :], usb.value, Rb.value)) \\\n",
    "           .collect()\n",
    "    ms = matrix(np.array(ms)[:, :, 0])      # collect() returns a list, so array ends up being\n",
    "                                            # a 3-d array, we take the first 2 dims for the matrix\n",
    "    # 广播更新后的item矩阵\n",
    "\tmsb = sc.broadcast(ms)\n",
    "\n",
    "\t# 固定item矩阵，分布式求解user矩阵\n",
    "    us = sc.parallelize(range(U), slices) \\\n",
    "           .map(lambda x: update(x, usb.value[x, :], msb.value, Rb.value.T)) \\\n",
    "           .collect()\n",
    "    us = matrix(np.array(us)[:, :, 0])\n",
    "    usb = sc.broadcast(us)\n",
    "\t\n",
    "\t# 平方误差\n",
    "    error = rmse(R, ms, us)\n",
    "\n",
    "# 最小二乘更新数据\n",
    "# 输入：矩阵行index，要更新的特征向量，固定的特征矩阵，评分矩阵\n",
    "def update(i, vec, mat, ratings):\n",
    "\tuu = mat.shape[0]\n",
    "\tff = mat.shape[1]\n",
    "\t\n",
    "\t# 变成可逆矩阵\n",
    "\tXtX = mat.T * mat\n",
    "\tXty = mat.T * ratings[i, :].T\n",
    "\n",
    "\t# 正则项\n",
    "\tfor j in range(ff):\n",
    "    \tXtX[j,j] += LAMBDA * uu\n",
    "\t\n",
    "\t# XtXZ=XtY，求Z并返回\n",
    "\t# 返回类型为二维数组。因为每次update只计算一个向量，所以实际只有第一维有值。\n",
    "\treturn np.linalg.solve(XtX, Xty)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.文献\n",
    "\n",
    "- [Large-scale Parallel Collaborative Filtering for the Netfli Prize](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.173.2797&rep=rep1&type=pdf)\n",
    "- [Collaborative Filtering for Implicit Feedback Datasets](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4781121)\n",
    "- [MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS](http://rakaposhi.eas.asu.edu/cse494/lsi-for-collab-filtering.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、具体实现及调用\n",
    "\n",
    "### 1. 模型调用\n",
    "##### 输入数据结构与说明：\n",
    "```python\n",
    "Rating(UserId:Int, ItemId:Int, Rating:toDouble) 用户、商品id必须为整形，评分为浮点型。\n",
    "```\n",
    "##### 模型输出数据结构及说明：\n",
    "```python\n",
    "RDD[(Id:Int, Array[feature:Double]]] 可以分别输出userFeatures和itemFeatures。包含id和隐含特征值。\n",
    "```\n",
    "##### 推荐结果输出数据结构及说明：\n",
    "```python\n",
    "Rating(UserId:Int, ItemId:Int, Rating:toDouble) 用户、商品id与预测评分。\n",
    "```\n",
    "##### 算法调用语句示例：\n",
    "```python\n",
    "import org.apache.spark.mllib.recommendation.ALS\n",
    "import org.apache.spark.mllib.recommendation.Rating\n",
    "\n",
    "// Load and parse the data\n",
    "val data = sc.textFile(\"mllib/data/als/test.data\")\n",
    "val ratings = data.map(_.split(',') match {\n",
    "\tcase Array(user, item, rate) =>  Rating(user.toInt, item.toInt, rate.toDouble)\n",
    "})\n",
    "\n",
    "// Build the recommendation model using ALS\n",
    "val numIterations = 20\n",
    "val model = ALS.train(ratings, 1, 20, 0.01)\n",
    "\n",
    "// Evaluate the model on rating data\n",
    "val usersProducts = ratings.map{ case Rating(user, product, rate)  => (user, product)}\n",
    "val predictions = model.predict(usersProducts).map{\n",
    "\tcase Rating(user, product, rate) => ((user, product), rate)\n",
    "}\n",
    "val ratesAndPreds = ratings.map{\n",
    "    case Rating(user, product, rate) => ((user, product), rate)\n",
    "}.join(predictions)\n",
    "val MSE = ratesAndPreds.map{\n",
    "\tcase ((user, product), (r1, r2)) =>  math.pow((r1- r2), 2)\n",
    "}.reduce(_ + _)/ratesAndPreds.count\n",
    "println(\"Mean Squared Error = \" + MSE)\n",
    "```\n",
    "##### 性能参数配置：\n",
    "```python\n",
    "val conf = new SparkConf()\n",
    "  .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "  .set(\"spark.kryo.registrator\",  classOf[ALSRegistrator].getName)\n",
    "\t/*\n",
    "\tWhether to track references to the same object when serializing data with Kryo, \n",
    "\twhich is necessary if your object graphs have loops \n",
    "\tand useful for efficiency if they contain multiple copies of the same object. \n",
    "\tCan be disabled to improve performance if you know this is not the case.\n",
    "\t*/\n",
    "  .set(\"spark.kryo.referenceTracking\", \"false\")\n",
    "  .set(\"spark.kryoserializer.buffer.mb\", \"8\")\n",
    "\t/*\n",
    "\tNumber of milliseconds to wait to launch a data-local task before giving up and launching it on a less-local node. \n",
    "\tYou should increase this setting if your tasks are long and see poor locality, but the default usually works well.\n",
    "\t*/\n",
    "  .set(\"spark.locality.wait\", \"10000\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、案例描述\n",
    "\n",
    "### 1. 业务问题描述及分析 \n",
    "#### 问题描述 \n",
    "在电子商务领域中，当用户面对大量的商品时，往往无法快速找到自己喜欢的商品，或者不是非常明确的知道自己喜欢商品。和搜索引擎相比的推荐系统通过研究用户的兴趣偏好，进行个性化计算，由系统发现用户的兴趣点，从而引导用户发现自己的需求。\n",
    "\n",
    "#### 简要分析 \n",
    "矩阵分解是推荐系统中非常重要的一种算法，它通过将用户对商品的评分矩阵（或者隐含数据），分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。如果用户所偏好特征，在商品上基本都出现，我们可以认为这个商品是用户喜欢的，进而可以将该商品推荐给用户。\n",
    "\n",
    "我们用历史的订单数据作为训练数据，来预测用户对未购买过的商品的偏好程度，将偏好程度最高topN的商品推荐给用户。\n",
    "\n",
    "### 2. 数据的准备\n",
    "\n",
    "图书品类下，2014年1月到5月的订单数据，取在14月和45月两个区间都有图书购物记录的用户。14月为训练数据，45月为测试数据。用户对商品有购买行为，则隐性反馈值为1。\n",
    "\n",
    "### 3. 算法的运行及模型生成\n",
    "\n",
    "#### 性能：\n",
    "\n",
    "N = User*Item N的最大值（理论估计+实际验证） 测试了两组数据集：\n",
    "第一组：\n",
    "\n",
    "训练： pair：6557620 用户：781030 商品：726490\n",
    "\n",
    "测试： pair：3250426 用户：781030 商品：490257\n",
    "\n",
    "N = 726490*781030 = 567410484700\n",
    "\n",
    "稀疏度 =pair/N = 0.0000115571\n",
    "worker-num,worker-mem,blocks,kryo,kryo-reference,locality-wait 等运行参数与数据量对一轮迭代时间的影响。\n",
    "运行时rdd的transform和action的运算时间与shuffle大小。\n",
    "#### 模型：\n",
    "\n",
    "##### 数据性质：\n",
    "\n",
    "稀疏性（行为（评分、购买），品类）\n",
    "##### 参数选择： lambda，alpha，R，iter\n",
    "\n",
    "### 4. 模型的评估\n",
    "\n",
    "#### 矩阵分解的评估\n",
    "\n",
    "原始矩阵为R，预测的为$\\tilde{R} = U^{T}V$，用RMSE来评估预测的效果。\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{\\sum (R - \\tilde{R})^{2}}{N}}$$\n",
    "\n",
    "其中N为中所有求和的项数\n",
    "\n",
    "#### 推荐效果的评估\n",
    "\n",
    "对推荐预测的效果一般用准确率(precision)和召回率(recall)来衡量。R(u)是根据用户在训练集上的行为给用户推荐的列表，T(u)是用户在测试集上的行为列表。则有\n",
    "\n",
    "召回率\n",
    "$$Recall = \\frac{\\sum_{u\\in U }\\left |R(u)\\bigcap T(u) \\right |}{\\sum_{u\\in U }\\left |T(u) \\right |}$$\n",
    "\n",
    "准确率\n",
    "$$Precise = \\frac{\\sum_{u\\in U }\\left |R(u)\\bigcap T(u) \\right |}{\\sum_{u\\in U }\\left |R(u) \\right |}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、与mahout的对比 ####mahout与spark性能对比\n",
    "\n",
    "数据量 6991409行，134M\n",
    "\n",
    "集群环境：mahout与spark安装在同一集群环境\n",
    "\n",
    "影响运行时间的参数：降维后的秩 30，迭代次数 30，mahout与spark设置相同\n",
    "\n",
    "运行时间：mahout(10个reduce) 运行180 minutes，spark 运行 40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
