{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64                            \n",
    "nb = 100000                         \n",
    "nq = 10000                          \n",
    "np.random.seed(1234)                \n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.   \n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_trained True\n",
      "is_trained True\n",
      "[[ 381  207  210  477]\n",
      " [ 526  911  142   72]\n",
      " [ 838  527 1290  425]\n",
      " [ 196  184  164  359]\n",
      " [ 526  377  120  425]]\n",
      "[[ 9900 10500  9309  9831]\n",
      " [11055 10895 10812 11321]\n",
      " [11353 11103 10164  9787]\n",
      " [10571 10664 10632  9638]\n",
      " [ 9628  9554 10036  9582]]\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(d)        \n",
    "\n",
    "print('is_trained',index.is_trained)\n",
    "index.add(xb)                       \n",
    "print('is_trained',index.is_trained) \n",
    "\n",
    "k = 4                               # k=4 k邻近搜索\n",
    "D, I = index.search(xq, k)          # 执行搜索\n",
    "print(I[:5])                        # 最初五次查询的结果\n",
    "print(I[-5:])                       # 最后五次查询的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndexFlatL2 是精确暴力搜索，后面的索引跟它相比即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndexIVFFlat-速度更快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集分割成多个，我们在d维空间中定义Voronoi单元，每个数据库向量落在其中一个单元格中。\n",
    "\n",
    "在搜索时，只有查询x所在的单元格中包含的数据库向量y和几个相邻的数据库向量y与查询向量进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_trained False\n",
      "is_trained True\n",
      "[[ 381  207  210  477]\n",
      " [ 526  911  142   72]\n",
      " [ 838  527 1290  425]\n",
      " [ 196  184  164  359]\n",
      " [ 526  377  120  425]]\n",
      "[[ 9900  9309  9810 10048]\n",
      " [11055 10895 10812 11321]\n",
      " [11353 10164  9787 10719]\n",
      " [10571 10664 10632 10203]\n",
      " [ 9628  9554  9582 10304]]\n"
     ]
    }
   ],
   "source": [
    "nlist = 100\n",
    "k = 4\n",
    "quantizer = faiss.IndexFlatL2(d)  # the other index\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "# here we specify METRIC_L2, by default it performs inner-product search\n",
    "\n",
    "print('is_trained',index.is_trained)\n",
    "index.train(xb)\n",
    "print('is_trained',index.is_trained) \n",
    "\n",
    "index.add(xb)                  # 添加索引可能会有一点慢\n",
    "D, I = index.search(xq, k)     # 搜索\n",
    "print(I[:5])                   # 最初五次查询的结果\n",
    "print(I[-5:])                  # 最后五次查询的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果和上面的强力搜索类似，但是不同。这是因为一些结果不在完全相同的Voronoi。因此，访问更多的单元格可能是有用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9900 10500  9309  9831]\n",
      " [11055 10895 10812 11321]\n",
      " [11353 11103 10164  9787]\n",
      " [10571 10664 10632  9638]\n",
      " [ 9628  9554 10036  9582]]\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 10              # 默认 nprobe 是1 ,可以设置的大一些试试\n",
    "D, I = index.search(xq, k)\n",
    "print(I[-5:])                  # 最后五次查询的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是正确的结果。\n",
    "\n",
    "但注意：在这种情况下获得完美的结果只是数据分布的一个假象，因为它在x轴上有一个强大的组件，这使得它更容易处理。nprobe参数始终是调整速度和结果精度之间权衡的一种方式。设置nprobe = nlist给出与强力搜索相同的结果（但较慢）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndexIVFPQ-更小空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到的索引IndexFlatL2和IndexIVFFlat都存储完整的向量。 \n",
    "\n",
    "为了扩展到非常大的数据集，Faiss提供了基于产品量化器的有损压缩来压缩存储的向量的变体。压缩的方法基于乘积量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 399  210  329 1619]\n",
      " [1193   39  911  187]\n",
      " [1267  197  527  425]\n",
      " [ 184  599  466  359]\n",
      " [ 828  377  120  416]]\n",
      "[[ 9900  8746  9853 10437]\n",
      " [10494 10507 11373  9014]\n",
      " [10719 11291 10424 10138]\n",
      " [10122  9638 11113 10630]\n",
      " [ 9229 10304  9644 10370]]\n"
     ]
    }
   ],
   "source": [
    "nlist = 100\n",
    "m = 8\n",
    "k = 4\n",
    "quantizer = faiss.IndexFlatL2(d)    # 内部的索引方式依然不变\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8) # 每个向量都被编码为8个字节大小\n",
    "\n",
    "index.train(xb)\n",
    "index.add(xb)\n",
    "\n",
    "index.nprobe = 10                   # 与以前的方法相比\n",
    "D, I = index.search(xq, k)          \n",
    "print(I[:5])                        # 最初五次查询的结果\n",
    "print(I[-5:])                       # 最后五次查询的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们可以观察到最近的邻居被正确地找到（它是矢量ID本身），但是向量自身的估计距离不是0，尽管它远远低于与其他邻居的距离。这是由于有损压缩。\n",
    "\n",
    "另外搜索真实查询时，虽然结果大多是错误的，但是它们在正确的空间区域，而对于真实数据，情况更好，因为：\n",
    "1. 统一数据很难进行索引，因为没有规律性可以被利用来聚集或降低维度\n",
    "2. 对于自然数据，语义最近邻居往往比不相关的结果更接近。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
